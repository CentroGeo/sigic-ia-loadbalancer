events {}

http {
  upstream llm_backend {
    # server 10.2.13.44:8001;
    # server 10.2.13.44:8001;
    # server 10.2.13.44:8001;
    # server 10.2.13.44:8001;
    server host.docker.internal:8001;
    server host.docker.internal:8001;
    server host.docker.internal:8001;
    server host.docker.internal:8001;
    server 10.2.5.5:8001;
  }
  
  server {

    listen 8080;

    location /v1/chat/completions {
      proxy_pass http://llm_backend/v1/chat/completions;
      
      #Tiempo de conexion
      proxy_connect_timeout 5s;

      #Tiempo de espera del servidor
      proxy_read_timeout 300s;

      #respuesta en caso de error
      proxy_next_upstream error timeout http_502 http_503 http_504 non_idempotent;

      #intento total por servidores en este caso no llega al 10.2.5.5
      #proxy_next_upstream_tries 3;

      proxy_intercept_errors on;
    }
  }
} 

#server 10.2.5.5:8001/v1/chat/completions max_fails=3 fail_timeout=10s; 
#limit_conn per_server 1;


#docker rm -f llm-lb

# docker run -d --name llm-lb \
#   -p 8080:8080 \
#   -v $(pwd)/nginx-conf/nginx.conf:/etc/nginx/nginx.conf:ro \
#   nginx

